{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "pd.options.mode.chained_assignment = None # suppress chained assignment warning\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import train_test_split as skl_ttsplit\n",
    "import sklearn.decomposition as skl_dcmp\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "from pyclustering.cluster.kmedoids import kmedoids as KMedoids\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "# Multiprocessing\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "price_data = pd.read_csv('../../data/sp500/sp500_since2000_prices.csv', index_col=0)\n",
    "price_data.index = pd.to_datetime(price_data.index)\n",
    "log_return_data = pd.read_csv('../../data/sp500/sp500_since2000_logreturns.csv', index_col=0)\n",
    "log_return_data.index = pd.to_datetime(log_return_data.index)\n",
    "\n",
    "# Get historical S&P 500 data\n",
    "index_history_data = pd.read_csv('../../data/sp500/sp500_history.csv', index_col=0)\n",
    "index_history_data.index  = pd.to_datetime(index_history_data.index)\n",
    "index_history_log_returns = np.log(index_history_data['Close'] / index_history_data['Close'].shift(1))\n",
    "index_history_log_returns_since2000 = index_history_log_returns['2000-01-01' :]\n",
    "\n",
    "# Get company data\n",
    "company_data = pd.read_csv('../../data/sp500/sp500_since2000_companies.csv')\n",
    "company_data_convert_dict = {'ggroup': 'Int32', 'gind': 'Int32', 'gsector': 'Int32', 'gsubind': 'Int32', 'naics': 'Int32', 'sic': 'Int32', 'spcindcd': 'Int32', 'spcseccd': 'Int32'}\n",
    "company_data = company_data.astype(company_data_convert_dict)\n",
    "tic_lookup_by_gvkey = company_data.set_index('gvkey')[['tic']].to_dict()['tic']\n",
    "gvkey_lookup_by_tic = company_data.set_index('tic')[['gvkey']].to_dict()['gvkey']\n",
    "\n",
    "# Detrend data\n",
    "log_return_data_detrended = pd.DataFrame(index = log_return_data.index, columns = log_return_data.columns)\n",
    "for tic in log_return_data.columns:\n",
    "    log_return_data_detrended[tic] = log_return_data[tic] -  index_history_log_returns_since2000\n",
    "\n",
    "# Year\n",
    "yearly_log_return_data = {}\n",
    "yearly_log_return_data_detrended = {}\n",
    "yearly_history_log_return_data = {}\n",
    "yearly_history_log_return_vola = {}\n",
    "for year in range(2000, 2021):\n",
    "    yearly_log_return_data[year] = log_return_data['{}-01-01'.format(year) : '{}-12-31'.format(year)]\n",
    "    yearly_log_return_data_detrended[year] = log_return_data_detrended['{}-01-01'.format(year) : '{}-12-31'.format(year)]\n",
    "    yearly_history_log_return_data[year] = index_history_log_returns_since2000['{}-01-01'.format(year) : '{}-12-31'.format(year)]\n",
    "    yearly_history_log_return_vola[year] = np.std(yearly_history_log_return_data[year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Hoberg Phillips reference data\n",
    "hp_line_regex = r'(?P<gvkey>\\d+)\\s+(?P<year>\\d+)\\s+(?P<icode25>\\d+)\\s+(?P<icode50>\\d+)\\s+(?P<icode100>\\d+)\\s+(?P<icode200>\\d+)\\s+(?P<icode300>\\d+)\\s+(?P<icode400>\\d+)\\s+(?P<icode500>\\d+)'\n",
    "\n",
    "yearly_HP_cluster_labels = {}\n",
    "fic_cluster_label = 'icode25'\n",
    "with open('../../data/hp/fic_data.txt') as file:\n",
    "    for line in file:\n",
    "        # get cluster for each company for each year\n",
    "        result = re.search(hp_line_regex, line)\n",
    "        if result is not None:\n",
    "            gvkey = int(result['gvkey'])\n",
    "            year = int(result['year'])\n",
    "            cluster_label = result[fic_cluster_label]\n",
    "            if gvkey in tic_lookup_by_gvkey: # if the company is also present in our data\n",
    "                if year not in yearly_HP_cluster_labels:\n",
    "                    yearly_HP_cluster_labels[year] = pd.DataFrame(columns=['tic', 'cluster_label'])\n",
    "                yearly_HP_cluster_labels[year] = yearly_HP_cluster_labels[year].append({'tic': tic_lookup_by_gvkey[gvkey], 'cluster_label': cluster_label}, ignore_index=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_HP_clusters = {}\n",
    "for year in yearly_HP_cluster_labels:\n",
    "    yearly_HP_clusters[year] = {}\n",
    "    for label in yearly_HP_cluster_labels[year]['cluster_label'].unique():\n",
    "        yearly_HP_clusters[year][label] = yearly_HP_cluster_labels[year][yearly_HP_cluster_labels[year]['cluster_label'] == label]['tic'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating correlation matrices for 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, Done!\n"
     ]
    }
   ],
   "source": [
    "# Pearson correlation matrix and euclidean distance\n",
    "yearly_correlations = {}\n",
    "yearly_correlations_detrended = {}\n",
    "yearly_average_correlation = {}\n",
    "yearly_average_correlation_detrended = {}\n",
    "\n",
    "yearly_euclidean = {}\n",
    "yearly_euclidean_detrended = {}\n",
    "yearly_available_companies = {} # companies for which data was available in this year\n",
    "\n",
    "# corr calculates the correlation matrix, dropna removes lines and columns with only NaN in them\n",
    "print('Calculating correlation matrices for ', end='')\n",
    "for year in yearly_log_return_data:\n",
    "    print('{}, '.format(year), end = '')\n",
    "    \n",
    "    yearly_correlations[year] = yearly_log_return_data[year].corr().dropna(how='all').dropna(how='all', axis=1)\n",
    "    yearly_correlations_detrended[year] = yearly_log_return_data_detrended[year].corr().dropna(how='all').dropna(how='all', axis=1)\n",
    "    \n",
    "    yearly_average_correlation[year] = yearly_correlations[year].sum(axis=0).sum() / len(yearly_correlations[year])**2\n",
    "    yearly_average_correlation_detrended[year] = yearly_correlations_detrended[year].sum(axis=0).sum() / len(yearly_correlations[year])**2\n",
    "    \n",
    "    yearly_euclidean[year] =  np.sqrt(2*(1-yearly_correlations[year] + 1e-15)).dropna(how='all').dropna(how='all', axis=1)\n",
    "    yearly_euclidean_detrended[year] =  2-np.sqrt(2*(1-yearly_correlations_detrended[year] + 1e-15)).dropna(how='all').dropna(how='all', axis=1)\n",
    "    \n",
    "    yearly_available_companies[year] = yearly_correlations[year].columns.to_list()\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating compatible output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "distmat_wildcard = r'sp500_yearly_distmat_{}.csv'\n",
    "for year in yearly_correlations_detrended:\n",
    "    # 1 - correlation for it to be a real distance\n",
    "    (1 - yearly_correlations_detrended[year]).to_csv(distmat_wildcard.format(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_filename = r'sp500_yearly_avg.csv'\n",
    "avg_detrended_filename = r'sp500_yearly_avg_detrended.csv'\n",
    "avg_correlation_frame = pd.DataFrame.from_dict(yearly_average_correlation, orient = 'index', columns = ['avg_corr'])\n",
    "avg_correlation_frame.index.name = 'year'\n",
    "avg_correlation_detrended_frame = pd.DataFrame.from_dict(yearly_average_correlation_detrended, orient = 'index', columns = ['avg_corr'])\n",
    "avg_correlation_detrended_frame.index.name = 'year'\n",
    "avg_correlation_frame.to_csv(avg_filename)\n",
    "avg_correlation_detrended_frame.to_csv(avg_detrended_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vola_filename = r'sp500_yearly_vola.csv'\n",
    "vola_frame = pd.DataFrame.from_dict(yearly_history_log_return_vola, orient = 'index', columns = ['vola'])\n",
    "vola_frame.index.name = 'year'\n",
    "vola_frame.to_csv(vola_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_wildcard = r'../hp/hp_yearly_clusters_{}.csv'\n",
    "for year in yearly_HP_cluster_labels:\n",
    "    yearly_HP_cluster_labels[year].to_csv(hp_wildcard.format(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
