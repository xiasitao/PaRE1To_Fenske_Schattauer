{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "pd.options.mode.chained_assignment = None # suppress chained assignment warning\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import train_test_split as skl_ttsplit\n",
    "import sklearn.decomposition as skl_dcmp\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "from pyclustering.cluster.kmedoids import kmedoids as KMedoids\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "# Multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify data directory here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name of files containing csvs of distance matrices, includes on label wildcard\n",
    "# Attention: the numbers in this file are 1 - correlation\n",
    "sp_distmat_wildcard = r'sp500/sp500_yearly_distmat_{}.csv'\n",
    "# labels/years of labels of the time series of distance matrices\n",
    "sp_labels = np.arange(2000, 2021)\n",
    "\n",
    "statement_distmat_wildcard = r'financial_statement/distance_matrices_combined3/cluster_{}.csv'\n",
    "statement_labels = np.arange(2000, 2021) \n",
    "\n",
    "hp_filename_wildcard = r'hp/hp_yearly_clusters_{}.csv'\n",
    "hp_labels = np.arange(1988, 2020)\n",
    "\n",
    "\n",
    "# Cluster sizes to process data for\n",
    "n_clusters_range = np.array([x for x in range(10, 100, 10)] + [x for x in range(100, 241, 20)])\n",
    "\n",
    "\n",
    "# Where to read cluster data from\n",
    "cluster_wildcard = r'clusters/yearly_clusters_{}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_data = pd.read_csv('company_data.csv')\n",
    "company_data_convert_dict = {'ggroup': 'Int32', 'gind': 'Int32', 'gsector': 'Int32', 'gsubind': 'Int32', 'naics': 'Int32', 'sic': 'Int32', 'spcindcd': 'Int32', 'spcseccd': 'Int32'}\n",
    "company_data = company_data.astype(company_data_convert_dict)\n",
    "tic_lookup_by_gvkey = company_data.set_index('gvkey')[['tic']].to_dict()['tic']\n",
    "gvkey_lookup_by_tic = company_data.set_index('tic')[['gvkey']].to_dict()['gvkey']\n",
    "\n",
    "yearly_sp_distmat = {}\n",
    "yearly_statement_distmat = {}\n",
    "yearly_hp_clusters = {}\n",
    "yearly_hp_cluster_labels = {}\n",
    "\n",
    "yearly_available_companies = {} # list of companies for which data was available in each year\n",
    "\n",
    "if sp_distmat_wildcard is not None:\n",
    "    for year in sp_labels:\n",
    "        yearly_sp_distmat[year] = pd.read_csv(sp_distmat_wildcard.format(year), index_col = 0)\n",
    "        yearly_available_companies[year] = yearly_sp_distmat[year].columns.to_list()\n",
    "\n",
    "if statement_distmat_wildcard is not None:\n",
    "    for year in statement_labels:\n",
    "        yearly_statement_distmat[year] = pd.read_csv(statement_distmat_wildcard.format(year), index_col = 0)\n",
    "        yearly_available_companies[year] += yearly_statement_distmat[year].columns.to_list()\n",
    "        yearly_available_companies[year] = list(dict.fromkeys(yearly_available_companies[year])) \n",
    "\n",
    "for year in hp_labels:\n",
    "    yearly_hp_cluster_labels[year] = pd.read_csv(hp_filename_wildcard.format(year))\n",
    "    yearly_hp_clusters[year] = {}\n",
    "    for label in yearly_hp_cluster_labels[year]['cluster_label'].unique():\n",
    "        yearly_hp_clusters[year][label] = yearly_hp_cluster_labels[year][yearly_hp_cluster_labels[year]['cluster_label'] == label]['tic'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Execute k-medoids for a pandas distance matrix.\n",
    "Returns: tuple of clusters, medoids. If return_idx, returns indices rather than pandas columns.\n",
    "\"\"\"\n",
    "def kmedoids_clustering(distance_matrix, n_clusters, return_idx = False):\n",
    "    kmedoids = KMedoids(\n",
    "        distance_matrix.to_numpy(),\n",
    "        initial_index_medoids = np.random.choice(len(distance_matrix), size=n_clusters, replace=True), \n",
    "        data_type = 'distance_matrix',\n",
    "        tolerance = 1e-5,\n",
    "        itermax = 1000,\n",
    "    )\n",
    "    kmedoids.process()\n",
    "    \n",
    "    kmedoids_medoids_idx = kmedoids.get_medoids()\n",
    "    kmedoids_medoids = distance_matrix.columns[kmedoids_medoids_idx].to_list()\n",
    "    kmedoids_clusters_idx = kmedoids.get_clusters()\n",
    "    kmedoids_clusters = []\n",
    "    for cluster in kmedoids_clusters_idx:\n",
    "        kmedoids_clusters.append(distance_matrix.columns[cluster].to_list())\n",
    "    \n",
    "    return (kmedoids_clusters_idx, kmedoids_medoids_idx) if return_idx else (kmedoids_clusters, kmedoids_medoids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GIC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only use ggroup and ggroup\n",
    "GIC_codes = company_data[['tic', 'gsector', 'ggroup']]\n",
    "GIC_codes.set_index('tic', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NAICS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAICS_codes = company_data[['tic', 'naics']]\n",
    "NAICS_codes['naics_2'] = NAICS_codes['naics'].apply(lambda s: int('{:04d}'.format(s)[0:2]) if not np.isnan(s) else np.NaN)\n",
    "NAICS_codes['naics_3'] = NAICS_codes['naics'].apply(lambda s: int('{:04d}'.format(s)[0:3]) if not np.isnan(s) else np.NaN)\n",
    "NAICS_codes['naics_4'] = NAICS_codes['naics'].apply(lambda s: int('{:04d}'.format(s)[0:4]) if not np.isnan(s) else np.NaN)\n",
    "NAICS_codes.set_index('tic', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIC**\n",
    "\n",
    "Attention: SIC 99 is a separate cluster! (https://mckimmoncenter.ncsu.edu/2digitsiccodes/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIC_codes = company_data[['tic', 'conm', 'sic']]\n",
    "SIC_codes['sic_1'] = SIC_codes['sic'].apply(lambda s: (int('{:04d}'.format(s)[0]) if s//100 != 99 else 10) if not np.isnan(s) else np.NaN)\n",
    "SIC_codes['sic_2'] = SIC_codes['sic'].apply(lambda s: int('{:04d}'.format(s)[0:2]) if not np.isnan(s) else np.NaN)\n",
    "\n",
    "yearly_SIC_clusters_1 = {}\n",
    "yearly_SIC_clusters_2 = {}\n",
    "for year in yearly_available_companies:\n",
    "    yearly_SIC_clusters_1[year] = {}\n",
    "    yearly_SIC_clusters_2[year] = {}\n",
    "    for sic_1 in SIC_codes['sic_1'].unique():\n",
    "        yearly_SIC_clusters_1[year][sic_1] = SIC_codes[SIC_codes['sic_1'] == sic_1]['tic'].to_list()\n",
    "    for sic_2 in SIC_codes['sic_2'].unique():\n",
    "        yearly_SIC_clusters_2[year][sic_2] = SIC_codes[SIC_codes['sic_2'] == sic_2]['tic'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SP Industry Sector / Economic Sector Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPC_codes = company_data[['tic', 'spcseccd', 'spcindcd']]\n",
    "SPC_codes.set_index('tic', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SP500**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class __clustering_wrapper:\n",
    "    def __init__(self, n, yearly_input):\n",
    "        self.n = n\n",
    "        self.yearly_input = yearly_input\n",
    "    def __call__(self, year):\n",
    "        return kmedoids_clustering(self.yearly_input[year], self.n)\n",
    "\n",
    "def clustering(yearly_input, n_clusters_range, threads = 5):\n",
    "    clusters = {}\n",
    "    medoids = {}\n",
    "    for n in n_clusters_range:\n",
    "        print('Clustering for n = {} ( '.format(n), end ='')\n",
    "        clusters[n] = {}\n",
    "        medoids[n] = {}\n",
    "        \n",
    "        if threads > 1:\n",
    "            # Multiprocessing\n",
    "            years = list(yearly_input.keys())\n",
    "            with Pool(threads) as pool:\n",
    "                result = pool.map(__clustering_wrapper(n, yearly_input), years)\n",
    "            for i, year in enumerate(years):\n",
    "                clusters[n][year] = result[i][0]\n",
    "                medoids[n][year] = result[i][1]\n",
    "            print('multiproc done ', end = '')\n",
    "        \n",
    "        else:\n",
    "            # Without Multiprocessing\n",
    "            for year in yearly_input:\n",
    "                print('{} '.format(year), end = '')\n",
    "                clusters[n][year], medoids[n][year] = kmedoids_clustering(yearly_input[year], n)\n",
    "        print(')')\n",
    "    return clusters, medoids\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KMedoids**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "yearly_sp_clusters, yearly_sp_medoids = clustering(yearly_sp_distmat, n_clusters_range)\n",
    "print('Elapsed while clustering SP500: {:.2f}'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "yearly_statement_clusters, yearly_statement_medoids = clustering(yearly_statement_distmat, n_clusters_range, threads=6)\n",
    "print('Elapsed while clustering statements: {:.2f}'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation into Monolithic Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['sic_1', 'sic_2', 'naics_2', 'naics_3', 'naics_4', 'gsector', 'ggroup', 'spcseccd', 'spcindcd', 'hp']\n",
    "columns += ['sp_{}'.format(n) for n in n_clusters_range]\n",
    "columns += ['st_{}'.format(n) for n in n_clusters_range]\n",
    "columns += ['ismedoid_sp_{}'.format(n) for n in n_clusters_range]\n",
    "columns += ['ismedoid_st_{}'.format(n) for n in n_clusters_range]\n",
    "cluster_dataframes = {}\n",
    "\n",
    "for year in np.arange(2000, 2021):\n",
    "    dataframe = pd.DataFrame(columns=columns, index = yearly_available_companies[year])\n",
    "    \n",
    "    dataframe['sic_1'] = SIC_codes.set_index('tic')['sic_1'].fillna(-1).astype('int')\n",
    "    dataframe['sic_2'] = SIC_codes.set_index('tic')['sic_2'].fillna(-1).astype('int')\n",
    "    \n",
    "    dataframe['naics_2'] = NAICS_codes['naics_2'].fillna(-1).astype('int')\n",
    "    dataframe['naics_3'] = NAICS_codes['naics_3'].fillna(-1).astype('int')\n",
    "    dataframe['naics_4'] = NAICS_codes['naics_4'].fillna(-1).astype('int')\n",
    "    \n",
    "    dataframe['gsector'] = GIC_codes['gsector'].fillna(-1).astype('int')\n",
    "    dataframe['ggroup'] = GIC_codes['ggroup'].fillna(-1).astype('int')\n",
    "    \n",
    "    dataframe['spcseccd'] = SPC_codes['spcseccd'].fillna(-1).astype('int')\n",
    "    dataframe['spcindcd'] = SPC_codes['spcindcd'].fillna(-1).astype('int')\n",
    "    \n",
    "    if year in yearly_hp_cluster_labels:\n",
    "        dataframe['hp'] = yearly_hp_cluster_labels[year].set_index('tic')['cluster_label'].fillna(-1).astype('int')\n",
    "        dataframe['hp'] = dataframe['hp'].fillna(-1).astype('int')\n",
    "    \n",
    "    # Transform k-Medoids cluster data format for tic lists to a label for each tic\n",
    "    for n in n_clusters_range:\n",
    "        if year in yearly_sp_clusters[n]:\n",
    "            # write cluster labels\n",
    "            for i, cluster in enumerate(yearly_sp_clusters[n][year]):\n",
    "                dataframe.at[cluster, 'sp_{}'.format(n)] = i\n",
    "            # mark medoids\n",
    "            dataframe.at[yearly_sp_medoids[n][year], 'ismedoid_sp_{}'.format(n)] = 1\n",
    "            dataframe['ismedoid_sp_{}'.format(n)].fillna(0, inplace=True)\n",
    "            \n",
    "        if year in yearly_statement_clusters[n]:\n",
    "            # write cluster labels\n",
    "            for i, cluster in enumerate(yearly_statement_clusters[n][year]):\n",
    "                dataframe.at[cluster, 'st_{}'.format(n)] = i\n",
    "            # mark medoids\n",
    "            dataframe.at[yearly_statement_medoids[n][year], 'ismedoid_st_{}'.format(n)] = 1\n",
    "            dataframe['ismedoid_st_{}'.format(n)].fillna(0, inplace=True)\n",
    "            \n",
    "    cluster_dataframes[year] = dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write output\n",
    "for year in cluster_dataframes:\n",
    "    cluster_dataframes[year].to_csv(cluster_wildcard.format(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
